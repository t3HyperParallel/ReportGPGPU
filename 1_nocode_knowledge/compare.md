# 比較

一般的にGPUでの処理がCPUでの処理より遅くなる理由は

+ 条件分岐・投機的実行ができない
+ データの転送に時間がかかる

であるとされている。
しかし実態は、次のようではないかと予想している。（見つけ次第追記）

+ 互換性の都合でデバイスコードを実行時にコンパイルしなければならない

## GPUは条件分岐ができない？

//ToDo 図を付ける
これは正確には間違いである。しかし実質的にそうであると言われるのには理由がある。
+ 実行位置の共有
ある程度の数のスレッド（現在のCUDAであれば1ワープ32スレッド）を単位としてまとめられていて、ワープ内で命令の実行位置を共有している。
従ってワープ内で別方向に命令を分岐させると所謂「条件分岐ができない」になってしまう。
このため、ワープ内のスレッドが同じ方向に分岐するように加減をしてやればこの問題は避けられる。
+ 同期待ち
ワープはそれぞれ非同期で動くため、同一のメモリ領域にアクセスする場合は待ちが必要になってくる。
そのため特定のワープだけが先行していても、同期の為に結局待ちが必要になることがある。
